{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1725971,"sourceType":"datasetVersion","datasetId":1024049}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-14T17:00:46.412516Z","iopub.execute_input":"2024-06-14T17:00:46.413128Z","iopub.status.idle":"2024-06-14T17:00:54.296665Z","shell.execute_reply.started":"2024-06-14T17:00:46.413096Z","shell.execute_reply":"2024-06-14T17:00:54.295439Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2024-06-14T17:00:29.639752Z","iopub.execute_input":"2024-06-14T17:00:29.640169Z","iopub.status.idle":"2024-06-14T17:00:46.410705Z","shell.execute_reply.started":"2024-06-14T17:00:29.640131Z","shell.execute_reply":"2024-06-14T17:00:46.409577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annotations_path = '/kaggle/input/kranoknv/Annotations'\nvideo_path = '/kaggle/input/kranoknv/Videos'","metadata":{"execution":{"iopub.status.busy":"2024-06-14T17:09:48.451031Z","iopub.execute_input":"2024-06-14T17:09:48.451568Z","iopub.status.idle":"2024-06-14T17:09:48.457900Z","shell.execute_reply.started":"2024-06-14T17:09:48.451529Z","shell.execute_reply":"2024-06-14T17:09:48.456276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Eda","metadata":{}},{"cell_type":"code","source":"\n# Function to load annotations\ndef load_annotations(annotations_path):\n    annotations = []\n    for file_name in os.listdir(annotations_path):\n        if file_name.endswith('.json'):\n            file_path = os.path.join(annotations_path, file_name)\n            with open(file_path, 'r') as f:\n                data = json.load(f)\n                for frame, frame_data in data.items():\n                    frame_number = int(frame.split('_')[-1])  # 'Frame_0000046' -> 46\n                    number_of_people = frame_data['numberOfPeople']\n                    for pedestrian_data in frame_data['pedestriansData']:\n                        try:\n                            bbox = list(map(int, pedestrian_data[:4]))  # Convert bbox coordinates to integers\n                            behavior = pedestrian_data[4]\n                        except KeyError as e:\n                            print(f\"Missing key {e} in annotation for frame {frame_number} in file {file_name}\")\n                            continue\n\n                        annotations.append({\n                            'video': file_name,\n                            'frame': frame_number,\n                            'num_pedestrians': number_of_people,\n                            'bbox': bbox,\n                            'behavior': behavior\n                        })\n    return pd.DataFrame(annotations)\n\n# Load annotations into a DataFrame\nannotations_df = load_annotations(annotations_path)\n\n# Display the first few rows of the DataFrame\nprint(annotations_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T17:09:51.511538Z","iopub.execute_input":"2024-06-14T17:09:51.511958Z","iopub.status.idle":"2024-06-14T17:10:23.821114Z","shell.execute_reply.started":"2024-06-14T17:09:51.511927Z","shell.execute_reply":"2024-06-14T17:10:23.819860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **video**: Videonun adı. Örneğin, Normal_00409.json dosyasının adı bu videonun \"Normal\" olarak etiketlendiğini ve belirli bir numara (00409) ile tanımlandığını gösterir.\n* **frame**: Çerçeve numarası. Bu, videodaki hangi kareye ait olduğunun numarasını gösterir.\n* **num_pedestrians**: O karede bulunan pedestrian (yaya) sayısı. Örnekte her zaman 1 değeri var, yani her karede sadece bir yaya var.\n* **bbox**: Bounding box koordinatları. Bu, pedestrian'ın görüntüde kapladığı alanı gösterir ve [x_min, y_min, x_max, y_max] formatında verilmiştir. Bu değerler, pedestrian'ın sol üst ve sağ alt köşe koordinatlarını belirtir.\n* **behavior**: Yaya davranışı. Bu örnekte her zaman Normal olarak belirtilmiş, yani bu karelerde görülen pedestrian normal davranış sergiliyor.","metadata":{}},{"cell_type":"code","source":"annotations_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T17:10:23.823401Z","iopub.execute_input":"2024-06-14T17:10:23.823851Z","iopub.status.idle":"2024-06-14T17:10:24.222959Z","shell.execute_reply.started":"2024-06-14T17:10:23.823810Z","shell.execute_reply":"2024-06-14T17:10:24.221835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"behavior_counts = annotations_df['behavior'].value_counts()\nprint(behavior_counts)\n\nplt.figure(figsize=(10, 6))\nsns.countplot(data=annotations_df, x='behavior', order=behavior_counts.index)\nplt.title('Davranış Türlerinin Dağılımı')\nplt.xlabel('Davranış Türü')\nplt.ylabel('Sayı')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T17:10:24.224480Z","iopub.execute_input":"2024-06-14T17:10:24.224918Z","iopub.status.idle":"2024-06-14T17:10:25.785946Z","shell.execute_reply.started":"2024-06-14T17:10:24.224878Z","shell.execute_reply":"2024-06-14T17:10:25.784747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pedestrians number for each frame\nplt.figure(figsize=(12, 6))\nsns.histplot(annotations_df['num_pedestrians'], bins=50, kde=True)\nplt.title('Her Çerçevedeki Yayaların Sayısı')\nplt.xlabel('Yaya Sayısı')\nplt.ylabel('Frekans')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T17:10:25.788581Z","iopub.execute_input":"2024-06-14T17:10:25.788971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annotations_df['bbox_width'] = annotations_df['bbox'].apply(lambda x: int(x[2]) - int(x[0]))\nannotations_df['bbox_height'] = annotations_df['bbox'].apply(lambda x: int(x[3]) - int(x[1]))\n\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nsns.histplot(annotations_df['bbox_width'], bins=50, kde=True)\nplt.title('BBox Genişliği Dağılımı')\nplt.xlabel('Genişlik')\nplt.ylabel('Frekans')\n\nplt.subplot(1, 2, 2)\nsns.histplot(annotations_df['bbox_height'], bins=50, kde=True)\nplt.title('BBox Yüksekliği Dağılımı')\nplt.xlabel('Yükseklik')\nplt.ylabel('Frekans')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.idle":"2024-06-14T17:10:44.302642Z","shell.execute_reply.started":"2024-06-14T17:10:31.293913Z","shell.execute_reply":"2024-06-14T17:10:44.301197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(annotations_df.describe())","metadata":{"execution":{"iopub.status.busy":"2024-06-14T17:10:44.304012Z","iopub.execute_input":"2024-06-14T17:10:44.304370Z","iopub.status.idle":"2024-06-14T17:10:44.468477Z","shell.execute_reply.started":"2024-06-14T17:10:44.304331Z","shell.execute_reply":"2024-06-14T17:10:44.467092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(annotations_df[['frame', 'num_pedestrians', 'bbox_width', 'bbox_height']])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-14T17:10:44.470056Z","iopub.execute_input":"2024-06-14T17:10:44.470517Z","iopub.status.idle":"2024-06-14T17:11:22.608367Z","shell.execute_reply.started":"2024-06-14T17:10:44.470476Z","shell.execute_reply":"2024-06-14T17:11:22.607060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_bbox_data(annotations_df):\n    bbox_data = []\n    labels = []\n    \n    for index, row in annotations_df.iterrows():\n        bbox = row['bbox']\n        label = row['behavior']\n        bbox_data.append(bbox)\n        labels.append(label)\n    \n    return np.array(bbox_data), np.array(labels)\n\nbbox_data, labels = extract_bbox_data(annotations_df)\n\n# Etiketleri sayısal değerlere dönüştürme\nlabel_map = {'Normal': 0, 'Violent': 1}\nlabels = np.array([label_map[label] for label in labels])\n\n# Veriyi eğitim ve test setlerine ayırma\nX_train, X_test, y_train, y_test = train_test_split(bbox_data, labels, test_size=0.2, random_state=42)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T17:34:00.271249Z","iopub.execute_input":"2024-06-14T17:34:00.271743Z","iopub.status.idle":"2024-06-14T17:35:11.332697Z","shell.execute_reply.started":"2024-06-14T17:34:00.271707Z","shell.execute_reply":"2024-06-14T17:35:11.331414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Modeli oluşturma\nmodel = Sequential()\nmodel.add(Dense(64, input_shape=(4,), activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\n# Modeli derleme\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Modeli eğitme\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T17:55:54.681405Z","iopub.execute_input":"2024-06-14T17:55:54.681859Z","iopub.status.idle":"2024-06-14T18:02:01.462931Z","shell.execute_reply.started":"2024-06-14T17:55:54.681823Z","shell.execute_reply":"2024-06-14T18:02:01.461778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_frames(video_path, output_dir):\n    cap = cv2.VideoCapture(video_path)\n    frame_count = 0\n    os.makedirs(output_dir, exist_ok=True)\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame_path = os.path.join(output_dir, f'frame_{frame_count:04d}.jpg')\n        cv2.imwrite(frame_path, frame)\n        frame_count += 1\n    \n    cap.release()\n    return frame_count\n\ndef predict_behavior(model, bbox_data):\n    prediction = model.predict(np.array([bbox_data]))[0]\n    return 'Violent' if np.argmax(prediction) == 1 else 'Normal'\n\nnew_video_dir = '/kaggle/input/kranoknv/Videos'\nnew_frames_dir = '/kaggle/working/new_frames'\n\nfor new_video_file in os.listdir(new_video_dir):\n    new_video_path = os.path.join(new_video_dir, new_video_file)\n    new_frame_count = extract_frames(new_video_path, new_frames_dir)\n    \n    for frame_num in range(new_frame_count):\n        frame_path = os.path.join(new_frames_dir, f'frame_{frame_num:04d}.jpg')\n        # Karedeki bounding box verilerini DataFrame'den yükleyebilirsiniz.\n        frame_annotations = annotations_df[annotations_df['frame'] == frame_num]\n        for _, row in frame_annotations.iterrows():\n            bbox_data = row['bbox']\n            behavior = predict_behavior(model, bbox_data)\n             print(f\"Frame {frame_num}:Behavior{behavior})","metadata":{"execution":{"iopub.status.busy":"2024-06-14T18:02:21.596623Z","iopub.execute_input":"2024-06-14T18:02:21.597031Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}